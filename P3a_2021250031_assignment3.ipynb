{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf3a4d1-ab59-4e8e-9a75-24e58cd3f6b7",
   "metadata": {},
   "source": [
    "<sub>Developed by SeongKu Kang, August 2025 ‚Äî Do not distribute</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4883b6c",
   "metadata": {},
   "source": [
    "# üìò Task 1: Product category classification with no label (Fixed BERT embeddings)\n",
    "\n",
    "In this notebook, we consider a **realistic but challenging scenario**: what if we have **no labeled data at all**?\n",
    "\n",
    "In many real-world applications, collecting labeled product-category data is expensive and slow.  \n",
    "Here, we explore how to bootstrap a classification system without any human-provided labels.  \n",
    "Your task is to fill in the blanks and design solutions for this \"zero-label\" setting.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Ideas (Guidelines)\n",
    "\n",
    "1. **Constructing Silver Labels**  \n",
    "   Since we have no ground-truth labels, we must create *weak supervision signals*.  \n",
    "   Possible strategies include:\n",
    "   - **Lexical similarity:** Compare product titles/descriptions with category names using sparse vectors.  \n",
    "   - **Embedding similarity:** Compare BERT embeddings for both products and labels.  \n",
    "   - **Ensemble approaches:** Combine multiple weak signals (e.g., weighted voting between lexical-based and embedding-based similarity).\n",
    "\n",
    "2. **Learning with Silver Labels**  \n",
    "   Once silver labels are generated, train a classifier as if they were real labels.  \n",
    "   To improve robustness, you may consider various techniques that we learned, including (but not limited to):\n",
    "   - **Self-training:** Train an initial model with silver labels, then use it to assign pseudo-labels to unlabeled data with high confidence.  \n",
    "   - **Label embedding models:** Instead of treating labels as arbitrary IDs, use semantic embeddings of label names to guide classification (e.g., inner-product classifier).\n",
    "   - **Consistency regularization:** Encourage the model to produce stable predictions under input perturbations (e.g., dropout noise, data augmentation). This helps prevent overfitting to noisy silver labels and promotes smoother decision boundaries.\n",
    "   - **Stabilizing model prediction using Ensemble:** To mitigate the noise from weak or unstable supervision, you can stabilize predictions through ensembling techniques (e.g., Temporal ensemble via EMA, independent model ensemble).\n",
    "\n",
    "---\n",
    "\n",
    "## Your Tasks\n",
    "\n",
    "1. Generate silver labels.\n",
    "2. Train a classifier using these silver labels and various learning strategies.\n",
    "  \n",
    "üí° *Hint:* Think of this as \"bootstrapping\" the learning process ‚Äî even noisy initial signals can become useful when combined with iterative refinement and stabilization techniques.\n",
    "\n",
    "\n",
    "‚ö†Ô∏è **Note**: Do **NOT** use the labeled training set provided in the previous notebook.  \n",
    "In this notebook, you must assume that **no labeled data exists**. Only the following resources are allowed:\n",
    "- Product metadata (titles, descriptions, etc.)\n",
    "- Category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075fd1a6-77ce-4a17-9a90-81764a85fa86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:51:30.812466Z",
     "iopub.status.busy": "2025-11-04T12:51:30.812180Z",
     "iopub.status.idle": "2025-11-04T12:51:32.457352Z",
     "shell.execute_reply": "2025-11-04T12:51:32.456333Z",
     "shell.execute_reply.started": "2025-11-04T12:51:30.812444Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f5937f-50c1-43de-b833-204caf5a4026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:51:33.130814Z",
     "iopub.status.busy": "2025-11-04T12:51:33.130497Z",
     "iopub.status.idle": "2025-11-04T12:51:33.134503Z",
     "shell.execute_reply": "2025-11-04T12:51:33.133832Z",
     "shell.execute_reply.started": "2025-11-04T12:51:33.130794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"dataset\") # Root dataset directory\n",
    "CORPUS_PATH = ROOT / \"corpus.jsonl\" # Product corpus file (JSON Lines): Each line contains a product ID and its associated text description.\n",
    "EMB_PATH = ROOT / \"corpus_bert_mean.pt\"\n",
    "\n",
    "# Task 1: Product category classification\n",
    "LABEL_MAP_PATH = ROOT / \"category_classification\" \n",
    "LABEL2ID_PATH = LABEL_MAP_PATH / \"label2labelid.json\" \n",
    "ID2LABEL_PATH = LABEL_MAP_PATH / \"labelid2label.json\" \n",
    "PID2LABEL_TEST_PATH = LABEL_MAP_PATH / \"pid2labelids_test.json\" \n",
    "LABEL_EMB_PATH = LABEL_MAP_PATH / \"category_labels_bert_mean.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c819562-37b3-4cf1-8969-9d559997458b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:51:33.645979Z",
     "iopub.status.busy": "2025-11-04T12:51:33.645708Z",
     "iopub.status.idle": "2025-11-04T12:51:34.193690Z",
     "shell.execute_reply": "2025-11-04T12:51:34.193106Z",
     "shell.execute_reply.started": "2025-11-04T12:51:33.645962Z"
    }
   },
   "outputs": [],
   "source": [
    "pid2text = load_corpus(CORPUS_PATH) # load corpus\n",
    "\n",
    "label2id = load_json(LABEL2ID_PATH)\n",
    "id2label = load_json(ID2LABEL_PATH)\n",
    "pid2label_test = load_json(PID2LABEL_TEST_PATH)\n",
    "\n",
    "# loading pre-trained embeddings\n",
    "corpus_data = torch.load(EMB_PATH)  # {\"ids\": [...], \"embeddings\": Tensor}\n",
    "pid_list = corpus_data[\"ids\"]\n",
    "pid2idx = {pid: i for i, pid in enumerate(pid_list)}\n",
    "embeddings = corpus_data[\"embeddings\"]\n",
    "\n",
    "label_data = torch.load(LABEL_EMB_PATH)\n",
    "label_emb = label_data[\"embeddings\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dfc6019-c824-4a6f-aff7-85c3668f473f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:51:34.602598Z",
     "iopub.status.busy": "2025-11-04T12:51:34.602167Z",
     "iopub.status.idle": "2025-11-04T12:51:34.605520Z",
     "shell.execute_reply": "2025-11-04T12:51:34.605002Z",
     "shell.execute_reply.started": "2025-11-04T12:51:34.602562Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Your Task: Do your magic below \n",
    "# =========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38337c7-4829-4dfe-8622-eb65092b464f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:51:35.731401Z",
     "iopub.status.busy": "2025-11-04T12:51:35.731216Z",
     "iopub.status.idle": "2025-11-04T12:51:35.739955Z",
     "shell.execute_reply": "2025-11-04T12:51:35.739430Z",
     "shell.execute_reply.started": "2025-11-04T12:51:35.731384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unlabeled dataset: provides product embeddings without labels\n",
    "class UnlabeledEmbeddingDataset(Dataset):\n",
    "    def __init__(self, pids, pid2idx, embeddings):\n",
    "        self.pids = list(pids)                       # list of product IDs\n",
    "        self.indices = [pid2idx[pid] for pid in self.pids]  # map PIDs to embedding indices\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"pid\": self.pids[idx], \"X\": self.embeddings[self.indices[idx]]}\n",
    "\n",
    "# Unlabeled dataset loader: provide embeddings of unlabeled products\n",
    "unlabeled_pids = pid_list\n",
    "unlabeled_dataset = UnlabeledEmbeddingDataset(unlabeled_pids, pid2idx, embeddings)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc5746a-d4e5-4d17-8cc6-966943cddf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:51:36.548264Z",
     "iopub.status.busy": "2025-11-04T12:51:36.548067Z",
     "iopub.status.idle": "2025-11-04T12:51:50.020107Z",
     "shell.execute_reply": "2025-11-04T12:51:50.019517Z",
     "shell.execute_reply.started": "2025-11-04T12:51:36.548246Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[silver-cand]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 617/617 [00:07<00:00, 85.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Silver-Candidates] kept 2155 / 39452 (5.46%), tau(adapt p86)=0.5841, margin>=0.06, cap=40\n"
     ]
    }
   ],
   "source": [
    "# Constructing Silver Labels\n",
    "import re, unicodedata, numpy as np, torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s.lower()).strip()\n",
    "    return s\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_silver_labels_candidates(\n",
    "    unlabeled_loader,\n",
    "    pid_list, pid2idx, pid2text,\n",
    "    label2id, label_emb,\n",
    "    K=28,                    # Number of label candidates selected by TF-IDF\n",
    "    alpha=0.6,               # Weighted combination of embedding and TF-IDF scores\n",
    "    pct=0.86,                # daptive threshold using a top percentile of mixed scores across the batch\n",
    "    margin_min=0.06,         # Minimum margin between top-1 and top-2 scores\n",
    "    cap_per_label=40,       # Per-label maximum picks\n",
    "    tfidf_kwargs=dict(min_df=2, max_df=0.95, ngram_range=(1,2), sublinear_tf=True, norm=\"l2\"),\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # 1) Prepare label texts (full path + duplicate the leaf name to up-weight it)\n",
    "    L = len(label2id)\n",
    "    label_full = [\"\"] * L\n",
    "    label_leaf = [\"\"] * L\n",
    "    for name, lid in label2id.items():\n",
    "        label_full[lid] = _norm(name)\n",
    "        leaf = name.split(\">\")[-1].strip()\n",
    "        label_leaf[lid] = _norm(leaf)\n",
    "\n",
    "    label_texts = [f\"{label_full[i]} {label_leaf[i]} {label_leaf[i]}\" for i in range(L)]\n",
    "\n",
    "    # 2) Build TF-IDF vectors (lexical view) to generate candidates\n",
    "    if tfidf_kwargs is None:\n",
    "        tfidf_kwargs = dict(min_df=2, max_df=0.95, ngram_range=(1,2), sublinear_tf=True, norm=\"l2\")\n",
    "    vectorizer = TfidfVectorizer(**tfidf_kwargs)\n",
    "    tfidf_labels = vectorizer.fit_transform(label_texts)                # [L, V]\n",
    "\n",
    "    prod_texts = [_norm(pid2text[pid]) for pid in pid_list]\n",
    "    tfidf_products = vectorizer.transform(prod_texts)                   # [N, V]\n",
    "\n",
    "    # 3) Compute cosine similarity in embedding space (with L2 normalization)\n",
    "    lab_norm = F.normalize(label_emb, dim=1)               # [L, d]\n",
    "    lab_norm_T = lab_norm.t().contiguous()\n",
    "\n",
    "    silver = {}\n",
    "    kept_per_label = defaultdict(int)\n",
    "\n",
    "    for batch in tqdm(unlabeled_loader, desc=\"[silver-cand]\"):\n",
    "        pids = batch[\"pid\"]\n",
    "        X    = batch[\"X\"].to(device)                       # [B, d]\n",
    "        rows = [pid2idx[pid] for pid in pids]\n",
    "\n",
    "        # 3-1) Select top-K label candidates by TF-IDF (use sparse argpartition to save memory)\n",
    "        sims_tfidf = (tfidf_products[rows]).dot(tfidf_labels.T)        # [B, L] (sparse)\n",
    "        topK_idx = []\n",
    "        topK_tfs = []\n",
    "        for i in range(sims_tfidf.shape[0]):\n",
    "            row = sims_tfidf.getrow(i)\n",
    "            if row.nnz == 0:\n",
    "                topK_idx.append(np.array([], dtype=int))\n",
    "                topK_tfs.append(np.array([], dtype=float))\n",
    "                continue\n",
    "            idx = row.indices\n",
    "            dat = row.data\n",
    "            if len(idx) > K:\n",
    "                part = np.argpartition(dat, -K)[-K:]\n",
    "                order = part[np.argsort(dat[part])[::-1]]\n",
    "                idx = idx[order]; dat = dat[order]\n",
    "            else:\n",
    "                order = np.argsort(dat)[::-1]\n",
    "                idx = idx[order]; dat = dat[order]\n",
    "            topK_idx.append(idx)\n",
    "            topK_tfs.append(dat)\n",
    "\n",
    "        # 3-2) Compute embedding scores only for the candidates, then mix with TF-IDF scores\n",
    "        Xn = F.normalize(X, dim=1)                                     # [B, d]\n",
    "        top1 = []; top2 = []\n",
    "        for bi, pid in enumerate(pids):\n",
    "            cand = topK_idx[bi]\n",
    "            if cand.size == 0:\n",
    "                continue\n",
    "            # emb score for candidates only\n",
    "            emb_scores = (Xn[bi].unsqueeze(0) @ lab_norm[cand].T).squeeze(0).cpu().numpy()  # [k]\n",
    "            mix = alpha * emb_scores + (1-alpha) * topK_tfs[bi]                             # [k]\n",
    "            # top1/top2 and margin\n",
    "            ord_ = np.argsort(mix)[::-1]\n",
    "            l1, c1 = int(cand[ord_[0]]), float(mix[ord_[0]])\n",
    "            c2 = float(mix[ord_[1]]) if len(ord_) > 1 else 0.0\n",
    "            top1.append(c1); top2.append(c2)\n",
    "            silver[pid] = (l1, c1, c2)\n",
    "\n",
    "    # 4) Adaptive selection using percentile threshold + margin + per-label cap\n",
    "    # Estimate the percentile threshold from the global score distribution (not per-batch)\n",
    "    conf_all = np.array([v[1] for v in silver.values()], dtype=float)\n",
    "    if conf_all.size == 0:\n",
    "        print(\"[silver-cand] no candidates; relax K/alpha or vectorizer params.\")\n",
    "        return {}\n",
    "\n",
    "    tau_adapt = float(np.quantile(conf_all, pct))\n",
    "    final = {}\n",
    "    for pid, (lab, c1, c2) in silver.items():\n",
    "        if c1 >= tau_adapt and (c1 - c2) >= margin_min and kept_per_label[lab] < cap_per_label:\n",
    "            final[pid] = (lab, c1)\n",
    "            kept_per_label[lab] += 1\n",
    "\n",
    "    print(f\"[Silver-Candidates] kept {len(final)} / {len(pid_list)} \"\n",
    "          f\"({len(final)/len(pid_list):.2%}), \"\n",
    "          f\"tau(adapt p{int(pct*100)})={tau_adapt:.4f}, margin>={margin_min}, cap={cap_per_label}\")\n",
    "    return silver\n",
    "\n",
    "\n",
    "silver = build_silver_labels_candidates(\n",
    "    unlabeled_loader, pid_list, pid2idx, pid2text, label2id, label_emb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdee5f4-af9f-488d-8e72-271092373a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:52:00.068349Z",
     "iopub.status.busy": "2025-11-04T12:52:00.068076Z",
     "iopub.status.idle": "2025-11-04T12:52:00.090153Z",
     "shell.execute_reply": "2025-11-04T12:52:00.089610Z",
     "shell.execute_reply.started": "2025-11-04T12:52:00.068329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build Silver Labeled Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class SilverLabeledDataset(Dataset):\n",
    "    def __init__(self, pid_list, pid2idx, embeddings, silver):\n",
    "        # silver: {pid: (label_id, confidence)}\n",
    "        self.items = [(pid, silver[pid][0]) for pid in pid_list if pid in silver]\n",
    "        self.indices = [pid2idx[pid] for pid,_ in self.items]\n",
    "        self.embeddings = embeddings\n",
    "        self.y = torch.tensor([lab for _, lab in self.items], dtype=torch.long)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = self.embeddings[self.indices[i]]\n",
    "        y = self.y[i]\n",
    "        return {\"X\": x, \"y\": y}\n",
    "\n",
    "silver_train_dataset = SilverLabeledDataset(pid_list, pid2idx, embeddings, silver)\n",
    "\n",
    "# Split into train/validation sets (80% / 20%)\n",
    "val_ratio = 0.2\n",
    "val_size = int(len(silver_train_dataset) * val_ratio)\n",
    "train_size = len(silver_train_dataset) - val_size\n",
    "\n",
    "train_split, val_split = random_split(silver_train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_split, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_split, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9e4f64-da1e-48e0-bad6-1b69b9d1d689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:52:01.401083Z",
     "iopub.status.busy": "2025-11-04T12:52:01.400837Z",
     "iopub.status.idle": "2025-11-04T12:52:01.408370Z",
     "shell.execute_reply": "2025-11-04T12:52:01.407836Z",
     "shell.execute_reply.started": "2025-11-04T12:52:01.401061Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProductCategoryEmbeddingDataset(Dataset):\n",
    "    def __init__(self, pid2label, pid2idx, embeddings):\n",
    "        self.pids = list(pid2label.keys())\n",
    "        self.labels = [pid2label[pid] for pid in self.pids]\n",
    "        self.indices = [pid2idx[pid] for pid in self.pids]\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = self.embeddings[self.indices[idx]]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return {\"X\": emb, \"y\": label}\n",
    "\n",
    "# Build test dataset and dataloader from precomputed embeddings\n",
    "test_dataset = ProductCategoryEmbeddingDataset(pid2label_test, pid2idx, embeddings)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Model dimensions\n",
    "input_dim = embeddings.shape[1]   # Size of embedding vector (feature dimension)\n",
    "num_classes = len(label2id)       # Number of category classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3dccced-5796-4d1b-a058-978b1dcdb7b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:52:01.977029Z",
     "iopub.status.busy": "2025-11-04T12:52:01.976810Z",
     "iopub.status.idle": "2025-11-04T12:52:02.727162Z",
     "shell.execute_reply": "2025-11-04T12:52:02.726567Z",
     "shell.execute_reply.started": "2025-11-04T12:52:01.977009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pseudo-labeled dataset: stores embeddings with assigned pseudo-labels for training\n",
    "class TensorDatasetFromVectors(Dataset):\n",
    "    def __init__(self, X_list, y_list):\n",
    "        self.X = torch.stack(X_list)                      # list of embeddings -> tensor\n",
    "        self.y = torch.tensor(y_list, dtype=torch.long)   # pseudo-labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"X\": self.X[idx], \"y\": self.y[idx]}       # embedding + pseudo-label\n",
    "\n",
    "# Classifier that uses label embeddings to make predictions\n",
    "class InnerProductClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, label_embeddings, trainable_label_emb=True):\n",
    "        super().__init__()\n",
    "        # Project input features into the same dimension as label embeddings\n",
    "        self.proj = nn.Linear(input_dim, label_embeddings.size(1))\n",
    "\n",
    "        if trainable_label_emb:\n",
    "            # Label embeddings are trainable parameters\n",
    "            self.label_emb = nn.Parameter(label_embeddings.clone())\n",
    "        else:\n",
    "            # Label embeddings are fixed (not updated during training)\n",
    "            self.register_buffer(\"label_emb\", label_embeddings.clone())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project input feature vectors\n",
    "        x_proj = self.proj(x)\n",
    "        # Compute logits as similarity with each label embedding\n",
    "        logits = torch.matmul(x_proj, self.label_emb.T)\n",
    "        return logits\n",
    "\n",
    "model = InnerProductClassifier(input_dim, label_emb).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4937e002-6aa5-4a5f-88b2-2fdae64ddb78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:52:02.728144Z",
     "iopub.status.busy": "2025-11-04T12:52:02.727905Z",
     "iopub.status.idle": "2025-11-04T12:52:02.739661Z",
     "shell.execute_reply": "2025-11-04T12:52:02.739167Z",
     "shell.execute_reply.started": "2025-11-04T12:52:02.728127Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y = batch[\"y\"].to(device)\n",
    "            logits = model(X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b05d7a9-6725-4b75-a385-bb778e0ad27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:52:02.740228Z",
     "iopub.status.busy": "2025-11-04T12:52:02.740078Z",
     "iopub.status.idle": "2025-11-04T12:52:53.607577Z",
     "shell.execute_reply": "2025-11-04T12:52:53.606970Z",
     "shell.execute_reply.started": "2025-11-04T12:52:02.740212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 3.5319\n",
      "[VAL ] Acc: 0.3460 | F1-macro: 0.0964 *\n",
      "[TEST] Acc: 0.1057 | F1-macro: 0.0623\n",
      "[Epoch 2] Train Loss: 2.7389\n",
      "[VAL ] Acc: 0.3979 | F1-macro: 0.1481 *\n",
      "[TEST] Acc: 0.1328 | F1-macro: 0.0857\n",
      "  + Added 202 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 3] Train Loss: 2.4117\n",
      "[VAL ] Acc: 0.4246 | F1-macro: 0.1919 *\n",
      "[TEST] Acc: 0.1653 | F1-macro: 0.1150\n",
      "[Epoch 4] Train Loss: 2.2078\n",
      "[VAL ] Acc: 0.4409 | F1-macro: 0.2154 *\n",
      "[TEST] Acc: 0.1714 | F1-macro: 0.1230\n",
      "  + Added 532 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 5] Train Loss: 2.0224\n",
      "[VAL ] Acc: 0.4501 | F1-macro: 0.2281 *\n",
      "[TEST] Acc: 0.1619 | F1-macro: 0.1203\n",
      "[Epoch 6] Train Loss: 1.8967\n",
      "[VAL ] Acc: 0.4566 | F1-macro: 0.2322 *\n",
      "[TEST] Acc: 0.1692 | F1-macro: 0.1316\n",
      "  + Added 1523 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 7] Train Loss: 1.7127\n",
      "[VAL ] Acc: 0.4719 | F1-macro: 0.2533 *\n",
      "[TEST] Acc: 0.1802 | F1-macro: 0.1470\n",
      "[Epoch 8] Train Loss: 1.6308\n",
      "[VAL ] Acc: 0.4535 | F1-macro: 0.2379\n",
      "[TEST] Acc: 0.1689 | F1-macro: 0.1334\n",
      "  + Added 1749 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 9] Train Loss: 1.4780\n",
      "[VAL ] Acc: 0.4677 | F1-macro: 0.2682\n",
      "[TEST] Acc: 0.1944 | F1-macro: 0.1552\n",
      "[Epoch 10] Train Loss: 1.4150\n",
      "[VAL ] Acc: 0.4866 | F1-macro: 0.2761 *\n",
      "[TEST] Acc: 0.1825 | F1-macro: 0.1454\n",
      "  + Added 1980 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 11] Train Loss: 1.2834\n",
      "[VAL ] Acc: 0.4838 | F1-macro: 0.2776\n",
      "[TEST] Acc: 0.1931 | F1-macro: 0.1528\n",
      "[Epoch 12] Train Loss: 1.2376\n",
      "[VAL ] Acc: 0.4877 | F1-macro: 0.2756 *\n",
      "[TEST] Acc: 0.1798 | F1-macro: 0.1467\n",
      "  + Added 2648 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 13] Train Loss: 1.1112\n",
      "[VAL ] Acc: 0.4954 | F1-macro: 0.2914 *\n",
      "[TEST] Acc: 0.1960 | F1-macro: 0.1639\n",
      "[Epoch 14] Train Loss: 1.0722\n",
      "[VAL ] Acc: 0.4903 | F1-macro: 0.2887\n",
      "[TEST] Acc: 0.2008 | F1-macro: 0.1619\n",
      "  + Added 3126 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 15] Train Loss: 0.9568\n",
      "[VAL ] Acc: 0.4902 | F1-macro: 0.2951\n",
      "[TEST] Acc: 0.2008 | F1-macro: 0.1600\n",
      "[Epoch 16] Train Loss: 0.9276\n",
      "[VAL ] Acc: 0.4843 | F1-macro: 0.3018\n",
      "[TEST] Acc: 0.2069 | F1-macro: 0.1641\n",
      "  + Added 3574 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 17] Train Loss: 0.8309\n",
      "[VAL ] Acc: 0.5000 | F1-macro: 0.3037 *\n",
      "[TEST] Acc: 0.2001 | F1-macro: 0.1658\n",
      "[Epoch 18] Train Loss: 0.8046\n",
      "[VAL ] Acc: 0.4952 | F1-macro: 0.2932\n",
      "[TEST] Acc: 0.1861 | F1-macro: 0.1588\n",
      "  + Added 4886 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 19] Train Loss: 0.7104\n",
      "[VAL ] Acc: 0.5053 | F1-macro: 0.3154 *\n",
      "[TEST] Acc: 0.2089 | F1-macro: 0.1713\n",
      "[Epoch 20] Train Loss: 0.6883\n",
      "[VAL ] Acc: 0.4920 | F1-macro: 0.2943\n",
      "[TEST] Acc: 0.1850 | F1-macro: 0.1543\n",
      "  + Added 6286 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 21] Train Loss: 0.5998\n",
      "[VAL ] Acc: 0.4985 | F1-macro: 0.3136\n",
      "[TEST] Acc: 0.2112 | F1-macro: 0.1717\n",
      "[Epoch 22] Train Loss: 0.5816\n",
      "[VAL ] Acc: 0.4989 | F1-macro: 0.3047\n",
      "[TEST] Acc: 0.2001 | F1-macro: 0.1634\n",
      "  + Added 6249 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 23] Train Loss: 0.5137\n",
      "[VAL ] Acc: 0.5003 | F1-macro: 0.3077\n",
      "[TEST] Acc: 0.2046 | F1-macro: 0.1680\n",
      "[Epoch 24] Train Loss: 0.4994\n",
      "[VAL ] Acc: 0.5090 | F1-macro: 0.3069 *\n",
      "[TEST] Acc: 0.2012 | F1-macro: 0.1685\n",
      "  + Added 7736 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 25] Train Loss: 0.4384\n",
      "[VAL ] Acc: 0.5016 | F1-macro: 0.3043\n",
      "[TEST] Acc: 0.1893 | F1-macro: 0.1582\n",
      "[Epoch 26] Train Loss: 0.4247\n",
      "[VAL ] Acc: 0.4927 | F1-macro: 0.3194\n",
      "[TEST] Acc: 0.2188 | F1-macro: 0.1750\n",
      "  + Added 7972 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 27] Train Loss: 0.3780\n",
      "[VAL ] Acc: 0.5044 | F1-macro: 0.3049\n",
      "[TEST] Acc: 0.2082 | F1-macro: 0.1705\n",
      "[Epoch 28] Train Loss: 0.3672\n",
      "[VAL ] Acc: 0.5049 | F1-macro: 0.3171\n",
      "[TEST] Acc: 0.2055 | F1-macro: 0.1701\n",
      "  + Added 9427 pseudo-labeled samples (thr=0.95)\n",
      "[Epoch 29] Train Loss: 0.3245\n",
      "[VAL ] Acc: 0.4888 | F1-macro: 0.3170\n",
      "[TEST] Acc: 0.2096 | F1-macro: 0.1723\n",
      "[Early Stopping] No improvement for 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "# Training loop with self-training\n",
    "patience = 5\n",
    "pseudo_every = 2\n",
    "threshold = 0.95\n",
    "\n",
    "best_val_acc = -1\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "\n",
    "val_acc_list  = []\n",
    "test_acc_list = []\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    # Base training loop\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_cnt = 0\n",
    "    for batch in train_loader:\n",
    "        X = batch[\"X\"].to(device)\n",
    "        y = batch[\"y\"].to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        total_cnt += X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_cnt)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation & Test evaluation\n",
    "    val_result = evaluate(model, val_loader, device=device)\n",
    "    test_result = evaluate(model, test_loader, device=device)\n",
    "    val_acc = val_result[\"accuracy\"]\n",
    "    test_acc = test_result[\"accuracy\"]\n",
    "    val_acc_list.append(val_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print_eval_result(val_result, stage=\"val\", is_improved=(val_acc > best_val_acc))\n",
    "    print_eval_result(test_result, stage=\"test\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"[Early Stopping] No improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    # Pseudo-label generation (every x epochs)\n",
    "    if (epoch % pseudo_every) == 0:\n",
    "        model.eval()\n",
    "        picked_X, picked_y = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in unlabeled_loader:\n",
    "                X_ulb = batch[\"X\"].to(device)\n",
    "                probs = torch.softmax(model(X_ulb), dim=-1)\n",
    "                conf, pred = probs.max(dim=-1)\n",
    "                keep = conf >= threshold\n",
    "                if keep.any():\n",
    "                    kept = keep.nonzero(as_tuple=True)[0]\n",
    "                    picked_X.extend(X_ulb[kept].detach().cpu())\n",
    "                    picked_y.extend(pred[kept].detach().cpu().tolist())\n",
    "\n",
    "        if len(picked_X) > 0:\n",
    "            pseudo_ds = TensorDatasetFromVectors(picked_X, picked_y)\n",
    "            new_train_ds = ConcatDataset([train_loader.dataset, pseudo_ds])\n",
    "            train_loader = DataLoader(\n",
    "                new_train_ds,\n",
    "                batch_size=train_loader.batch_size,\n",
    "                shuffle=True\n",
    "            )\n",
    "            print(f\"  + Added {len(pseudo_ds)} pseudo-labeled samples (thr={threshold})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c187fb-307f-4395-994d-67ca060cabc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:52:58.551578Z",
     "iopub.status.busy": "2025-11-04T12:52:58.551325Z",
     "iopub.status.idle": "2025-11-04T12:52:58.606881Z",
     "shell.execute_reply": "2025-11-04T12:52:58.606337Z",
     "shell.execute_reply.started": "2025-11-04T12:52:58.551558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Evaluation on Best Model]\n",
      "[FINAL TEST] Acc: 0.2012 | F1-macro: 0.1685 *\n"
     ]
    }
   ],
   "source": [
    "# === Final Evaluation ===\n",
    "print(\"\\n[Final Evaluation on Best Model]\")\n",
    "model.load_state_dict(best_model_state)\n",
    "final_test_result = evaluate(model, test_loader, device=device)\n",
    "print_eval_result(final_test_result, stage=\"final test\", is_improved=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f00d5-c8dd-4fc3-9606-77bfd65911b3",
   "metadata": {},
   "source": [
    "## Prepare Kaggle submission\n",
    "Modify the code as needed to fit your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71561bc0-0903-49f5-affb-6bdafbde37ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T12:53:19.828476Z",
     "iopub.status.busy": "2025-11-04T12:53:19.828197Z",
     "iopub.status.idle": "2025-11-04T12:53:20.202830Z",
     "shell.execute_reply": "2025-11-04T12:53:20.202171Z",
     "shell.execute_reply.started": "2025-11-04T12:53:19.828456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to dataset/submission/P3_submission.csv\n",
      "           id  label\n",
      "0  B07X74M6PT    375\n",
      "1  B07FDRHFWM    160\n",
      "2  B07MQNYJKB    519\n",
      "3  B07GDQNZSV    375\n",
      "4  B08X43BL62    555\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# === 1. Load test IDs ===\n",
    "ROOT = Path(\"dataset\") # Root dataset directory\n",
    "LABEL_MAP_PATH = ROOT / \"category_classification\"\n",
    "TEST_IDS_PATH = LABEL_MAP_PATH / \"task1_test_ids.csv\"\n",
    "\n",
    "test_ids_df = pd.read_csv(TEST_IDS_PATH)  # has column \"id\"\n",
    "test_ids = test_ids_df[\"id\"].tolist()\n",
    "\n",
    "# === 2. Custom Dataset (no labels) ===\n",
    "class ProductCategoryTestDataset(Dataset):\n",
    "    def __init__(self, pids, pid2idx, embeddings):\n",
    "        self.pids = pids\n",
    "        self.indices = [pid2idx[pid] for pid in self.pids]\n",
    "        self.vecs = embeddings \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb = self.vecs[self.indices[idx]]\n",
    "        return {\"X\": torch.tensor(emb, dtype=torch.float)}\n",
    "\n",
    "# === 3. Build dataset and loader ===\n",
    "test_dataset_kaggle = ProductCategoryTestDataset(test_ids, pid2idx, embeddings)\n",
    "test_loader_kaggle = DataLoader(test_dataset_kaggle, batch_size=64)\n",
    "\n",
    "# === 4. Run predictions ===\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_kaggle:\n",
    "        X = batch[\"X\"].to(device)   # or \"cuda\" if using GPU\n",
    "        logits = model(X)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "# === 5. Build submission file ===\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"label\": all_preds\n",
    "})\n",
    "\n",
    "SUBMISSION_PATH = ROOT / \"submission/P3_submission.csv\"\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "print(f\"Submission file saved to {SUBMISSION_PATH}\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESCI Environment (Python 3.9)",
   "language": "python",
   "name": "esci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
